{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom transformers import BartForSequenceClassification, BartTokenizer\n\n# Load the BART model for sequence classification and the tokenizer\nmodel_name = \"facebook/bart-large\"\ntokenizer = BartTokenizer.from_pretrained(model_name)\nmodel = BartForSequenceClassification.from_pretrained(model_name, num_labels=1,device='cuda')\n\n# Function to predict a single value for the input text\ndef predict_value(text):\n    inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n    with torch.no_grad():  # Disable gradient calculation\n        logits = model(**inputs).logits  # Get the logits from the model\n    # Since we're predicting a single value, we apply a sigmoid to the logits\n    score = torch.sigmoid(logits).item()  # Convert to a single value\n    return score\n\n# Example usage\nif __name__ == \"__main__\":\n    input_text = \"\"\"\n    Natural language processing (NLP) is a subfield of artificial intelligence that focuses on the interaction between computers and humans through natural language.\n    The ultimate objective of NLP is to enable computers to understand, interpret, and generate human languages in a way that is valuable.\n    \"\"\"\n\n    # Predict a single value for the input\n    value = predict_value(input_text)\n    print(\"Predicted Value:\", value)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:51:32.090665Z","iopub.execute_input":"2024-09-25T15:51:32.091414Z","iopub.status.idle":"2024-09-25T15:51:34.879518Z","shell.execute_reply.started":"2024-09-25T15:51:32.091374Z","shell.execute_reply":"2024-09-25T15:51:34.878572Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Predicted Value: 0.518907904624939\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}